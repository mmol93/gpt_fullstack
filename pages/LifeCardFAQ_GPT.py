from typing import Dict, List
from uuid import UUID
from langchain.document_loaders import SitemapLoader
from langchain.schema.output import LLMResult
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
import streamlit as st
import os
from langchain.storage import LocalFileStore
import pickle
from langchain.callbacks.base import BaseCallbackHandler

project_root_path = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
faq_caching_embedding_check_path = os.path.join(project_root_path, ".cache/lifecard")
faq_caching_embedding_path = LocalFileStore("./.cache/lifecard/")
faq_caching_web_cache_folder_path_pickle = os.path.join(
    project_root_path, ".cache/lifecard_faq_web"
)
faq_caching_file_path_pickle = os.path.join(
    project_root_path, ".cache/lifecard_faq_web/lifecard_faq_web.pkl"
)
life_faq_sitemap_url = "https://lifecard.dga.jp/sitemap.xml"


class ChatCallbackHandler(BaseCallbackHandler):
    message = ""

    # *argsëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë°›ëŠ” ëª¨ë“  ì¸ìë¥¼ ì˜ë¯¸
    # **kwargsëŠ” key-value í˜•íƒœë¡œ ë°›ëŠ” ëª¨ë“  ì¸ìë¥¼ ì˜ë¯¸(ì˜ˆ: a=1, b=2...)
    def on_llm_start(self, *args, **kargs):
        # aiê°€ ë§í•˜ëŠ” ê²ƒì„ ë‹´ê¸° ìœ„í•œ ë¹ˆ ìƒì ìœ„ì ¯ì„ ë§Œë“ ë‹¤.
        self.message_box = st.empty()

    def on_llm_end(self, *args, **kargs):
        # aië¡œ ë‹µë³€ ì‘ì„±ì´ ëë‚¬ìœ¼ë©´ ë‹µë³€ì„ ì €ì¥í•œë‹¤.
        save_message(self.message, "ai")

    def on_llm_new_token(self, token, *arg, **kwargs):
        # í† í°ì„ ë°›ì„ ë•Œë§ˆë‹¤ ê¸°ì¡´ ë©”ì‹œì§€ì— ë¶™ì´ë„ë¡ í•œë‹¤.
        self.message += token
        self.message_box.markdown(self.message)


def save_message(message, role):
    st.session_state["messages"].append({"message": message, "role": role})


def send_message(message, role, save=True):
    with st.chat_message(role):
        st.markdown(message)
    if save:
        save_message(message=message, role=role)


# ì´ë•Œê¹Œì§€ ì…ë ¥í•œ ì±„íŒ… ë‚´ì—­ì„ ì¶œë ¥
def paint_history():
    for message in st.session_state["messages"]:
        send_message(
            message=message["message"],
            role=message["role"],
            save=False,
        )


llm = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[ChatCallbackHandler()])

# Map Re-rankë¥¼ ì‹¤ì‹œí•˜ëŠ” prompt
answers_prompt = ChatPromptTemplate.from_template(
"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’ä½¿ç”¨ã—ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã‚’çµ¶å¯¾ã«å®ˆã£ã¦ãã ã•ã„ã€‚
ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}

ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã‚’çµ¶å¯¾ã«å®ˆã£ã¦ãã ã•ã„ã€‚

1. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è³ªå•ã«å¯¾ã™ã‚‹ç­”ãˆãŒãªã„ã¨æ€ã£ãŸã‚‰ã€Œåˆ†ã‹ã‚Šã¾ã›ã‚“ã€‚ã€ã£ã¦è¨€ã£ã¦ãã ã•ã„ã€‚
2. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ã‚ã‚‹Listã§è³ªå•ã«æœ€ã‚‚é©åˆ‡ãªé …ç›®ã‚’é¸ã‚“ã§ãã®ãƒ‡ãƒ¼ã‚¿ã¨Sourceã‚’ä¸€ç·’ã«è¿”äº‹ã—ã¦ãã ã•ã„ã€‚
3. è¿”äº‹ã¯Markdownã®*ã‚’åˆ©ç”¨ã—åˆ†ã‹ã‚Šã‚„ã™ãã—ã¦ãã ã•ã„ã€‚
4. æ™®é€šã®æŒ¨æ‹¶ã¯æŒ¨æ‹¶ã§è¿”äº‹ã™ã‚‹ã ã‘ã§ã„ã„ã€‚

ä¾‹ï¼š
* è¤‡æ•°å›ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã€ãƒ­ã‚°ã‚¤ãƒ³ã§ããªã„å ´åˆã¯ä¸€å®šæ™‚é–“ç©ºã‘ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚
* åˆ¶é™ãŒã‹ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
* ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®å†è¨­å®šã‚’ã—ã¦ã‚‚è§£é™¤ã•ã‚Œãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
* ãƒ­ã‚°ã‚¤ãƒ³IDã‚„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å¿˜ã‚ŒãŸå ´åˆã¯ã€ã‚«ãƒ¼ãƒ‰ç•ªå·ã‚„æœ‰åŠ¹æœŸé™ã€æš—è¨¼ç•ªå·ã€ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®å…¥åŠ›ãŒå¿…è¦ã§ã™ã€‚æš—è¨¼ç•ªå·ã‚„ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒåˆ†ã‹ã‚‰ãªã„å ´åˆã¯ãƒãƒ£ãƒƒãƒˆã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚
Link: https://lifecard.dga.jp/faq_detail.html?id=2676


è³ªå•: {question}
"""
)


def save_loaded_data(data, path):
    with open(path, "wb") as file:
        pickle.dump(data, file)


def open_loaded_data(path):
    with open(path, "rb") as file:
        return pickle.load(file)


def parse_page(soup):
    target_soup = soup.find("div", class_="faq-box")
    print(target_soup.text)
    return (
        str(target_soup.get_text())
        .replace("\n", " ")
        .replace("\xa0", " ")
        .replace("CloseSearch Submit Blog", "")
    )


@st.cache_data(show_spinner="Webãƒšãƒ¼ã‚¸ã€‚ã‹ã‚‰FAQãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ä¸­")
def load_website(url):
    # st.write(faq_caching_web_cache_folder_path_pickle)
    cached_file = os.listdir(faq_caching_web_cache_folder_path_pickle)
    if cached_file:
        # ìºì‹±ëœ ë°ì´í„°ê°€ ìˆì„ ê²½ìš°
        splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            chunk_size=1000, chunk_overlap=200
        )
        cached_embeddings = CacheBackedEmbeddings.from_bytes_store(
            OpenAIEmbeddings(), faq_caching_embedding_path
        )
        docs = open_loaded_data(faq_caching_file_path_pickle)
        vector_store = FAISS.from_documents(docs, cached_embeddings)
        # ìœ ì‚¬ë„ ê²°ê³¼ ìƒìœ„ 2ê°œë§Œ ë°˜í™˜í•˜ë„ë¡ ì„¤ì •
        return vector_store.as_retriever(search_kwargs={"k": 3})
    else:
        # ìºì‹±ëœ ë°ì´í„°ê°€ ì—†ì„ ê²½ìš°
        # ìºì‹±ëœ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì›¹ì—ì„œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë¡œë“œí•œë‹¤.
        splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            chunk_size=1000, chunk_overlap=200
        )
        loader = SitemapLoader(url, parsing_function=parse_page)
        loader.requests_per_second = 2
        docs = loader.load_and_split(text_splitter=splitter)
        save_loaded_data(docs, faq_caching_file_path_pickle)
        cached_embeddings = CacheBackedEmbeddings.from_bytes_store(
            OpenAIEmbeddings(), faq_caching_embedding_path
        )
        vector_store = FAISS.from_documents(docs, cached_embeddings)
        print("ë°‘ì— ì‘ì—… ë")
        return vector_store.as_retriever(search_kwargs={"k": 3})


st.set_page_config(
    page_title="LifeCardFAQ GPT",
    page_icon="ğŸ’³",
)


st.markdown(
    """
    # LifeCardFAQ GPT
            
    ã‚ˆã†ã“ãã€Œã‚ˆãã‚ã‚‹è³ªå•ã€ã®GPTã¸
"""
)
question = st.chat_input(
    "è³ªå•å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
)

if question:
    paint_history()
    send_message(message=question, role="human")
    retriever = load_website(life_faq_sitemap_url)
    chain = (
        ({"context": retriever, "question": RunnablePassthrough()})
        | answers_prompt
        | llm
    )

    with st.chat_message("ai"):
        chain.invoke(question)
else:
    st.session_state["messages"] = []
